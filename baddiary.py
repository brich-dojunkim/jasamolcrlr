import time
import random
import re
import pandas as pd
import os
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import urllib.parse

def setup_driver():
    """ì…€ë ˆëŠ„ ì›¹ë“œë¼ì´ë²„ ì„¤ì •"""
    # í¬ë¡¬ ì˜µì…˜ ì„¤ì •
    chrome_options = Options()
    chrome_options.add_argument("--headless")  # í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ (ë¸Œë¼ìš°ì € ì°½ í‘œì‹œ ì•ˆ í•¨)
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--window-size=1920,1080")
    chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36")
    
    # í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì •
    service = Service(ChromeDriverManager().install())
    driver = webdriver.Chrome(service=service, options=chrome_options)
    
    return driver

def extract_product_info(product_element):
    """ìƒí’ˆ ìš”ì†Œì—ì„œ ì •ë³´ ì¶”ì¶œ"""
    try:
        # ìƒí’ˆëª…
        product_name = ""
        try:
            product_name = product_element.find_element(By.CSS_SELECTOR, '.name a').text.strip()
        except NoSuchElementException:
            pass
        
        # ìƒí’ˆ URL
        product_url = ""
        try:
            product_url = product_element.find_element(By.CSS_SELECTOR, '.name a').get_attribute('href')
        except NoSuchElementException:
            pass
        
        # ìƒí’ˆ ì„¤ëª…
        product_desc = ''
        try:
            product_desc = product_element.find_element(By.CSS_SELECTOR, '.xans-record- [rel="ìƒí’ˆ ìš”ì•½ì„¤ëª…"] span:last-child').text.strip()
        except NoSuchElementException:
            pass
        
        # ì´ë¯¸ì§€ URL
        image_url = ''
        try:
            img_element = product_element.find_element(By.CSS_SELECTOR, '.thumbnail img')
            image_url = img_element.get_attribute('src')
            # ì´ë¯¸ì§€ê°€ ì§€ì—° ë¡œë”©ë˜ëŠ” ê²½ìš° í™•ì¸
            if not image_url or image_url == "":
                image_url = img_element.get_attribute('data-src')
        except NoSuchElementException:
            pass
        
        # ì •ê°€ (í• ì¸ì´ ìˆëŠ” ê²½ìš°)
        original_price = None
        try:
            price_element = product_element.find_element(By.CSS_SELECTOR, '.xans-record- [rel="íŒë§¤ê°€"] span')
            original_price_text = price_element.text.strip()
            if "ì›" in original_price_text:
                original_price = re.sub(r'[^\d]', '', original_price_text)
        except NoSuchElementException:
            pass
        
        # í• ì¸ê°€ (í• ì¸ì´ ìˆëŠ” ê²½ìš°)
        discounted_price = None
        try:
            discount_element = product_element.find_element(By.CSS_SELECTOR, '.xans-record- [rel="í• ì¸íŒë§¤ê°€"] span')
            discount_text = discount_element.text.strip()
            discount_match = re.search(r'(\d+,?\d+)ì›', discount_text)
            if discount_match:
                discounted_price = re.sub(r'[^\d]', '', discount_match.group(1))
        except NoSuchElementException:
            # í• ì¸ì´ ì—†ëŠ” ê²½ìš° ì›ë˜ ê°€ê²©ì„ íŒë§¤ê°€ë¡œ ì„¤ì •
            if original_price:
                discounted_price = original_price
                original_price = None
        
        # í• ì¸ìœ¨
        discount_rate = None
        try:
            sale_element = product_element.find_element(By.CSS_SELECTOR, '.xans-record- [rel="í• ì¸íŒë§¤ê°€"] span span')
            discount_text = sale_element.text.strip()
            discount_match = re.search(r'(\d+(?:\.\d+)?)', discount_text)
            if discount_match:
                discount_rate = discount_match.group(1)
        except NoSuchElementException:
            pass
            
        # ë˜ëŠ” discountrate í´ë˜ìŠ¤ì—ì„œ í• ì¸ìœ¨ ì¶”ì¶œ
        if not discount_rate:
            try:
                discount_rate_element = product_element.find_element(By.CSS_SELECTOR, '.discountrate span.per')
                discount_rate = discount_rate_element.text.strip()
            except NoSuchElementException:
                pass
        
        # ë¦¬ë·° ìˆ˜
        reviews = 0
        try:
            review_element = product_element.find_element(By.CSS_SELECTOR, '.snap_review_count')
            review_text = review_element.text
            review_match = re.search(r'ë¦¬ë·° : (\d+)', review_text)
            if review_match:
                reviews = int(review_match.group(1))
        except (NoSuchElementException, ValueError):
            pass
        
        # ìƒ‰ìƒ ì •ë³´
        colors = []
        try:
            color_chips = product_element.find_elements(By.CSS_SELECTOR, '.colorChip span.chips')
            for color in color_chips:
                color_style = color.get_attribute('style')
                if 'background-color:' in color_style:
                    color_value = re.search(r'background-color:(.*)', color_style).group(1).strip()
                    colors.append(color_value)
        except NoSuchElementException:
            pass
        
        # ì œí’ˆ ì •ë³´ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ì €ì¥
        product_info = {
            'ìƒí’ˆëª…': product_name,
            'ìƒí’ˆURL': product_url,
            'ìƒí’ˆì„¤ëª…': product_desc,
            'ì´ë¯¸ì§€URL': image_url,
            'ì •ê°€': original_price,
            'íŒë§¤ê°€': discounted_price if discounted_price else original_price,
            'í• ì¸ìœ¨': discount_rate,
            'ë¦¬ë·°ìˆ˜': reviews,
            'ìƒ‰ìƒ': ', '.join(colors)
        }
        
        return product_info
    
    except Exception as e:
        print(f"ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def crawl_products(url, category_info, max_pages=None):
    """ì…€ë ˆëŠ„ì„ ì‚¬ìš©í•˜ì—¬ ìƒí’ˆ ì •ë³´ í¬ë¡¤ë§"""
    driver = setup_driver()
    all_products = []
    
    # ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¶”ì¶œ
    main_category = category_info['main_category']
    sub_category = category_info['sub_category']
    category_name = f"{main_category} > {sub_category}" if sub_category else main_category
    
    try:
        # ì²« í˜ì´ì§€ ë¡œë“œ
        driver.get(url)
        time.sleep(3)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
        
        # ì´ ìƒí’ˆ ê°œìˆ˜ í™•ì¸
        try:
            total_element = WebDriverWait(driver, 10).until(
                EC.presence_of_element_located((By.CSS_SELECTOR, '.prdCount strong'))
            )
            total_items = int(total_element.text)
            print(f"[{category_name}] ì´ ìƒí’ˆ ê°œìˆ˜: {total_items}")
        except (TimeoutException, ValueError) as e:
            print(f"[{category_name}] ì´ ìƒí’ˆ ê°œìˆ˜ë¥¼ í™•ì¸í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            total_items = 0
        
        # í˜ì´ì§€ë„¤ì´ì…˜ í™•ì¸
        try:
            pagination = driver.find_elements(By.CSS_SELECTOR, '.ec-base-paginate li a')
            max_page_found = 1
            
            for page_link in pagination:
                try:
                    page_num = int(page_link.text.strip())
                    max_page_found = max(max_page_found, page_num)
                except ValueError:
                    # ìˆ«ìê°€ ì•„ë‹Œ í˜ì´ì§€ ë§í¬ (ì˜ˆ: ë‹¤ìŒ, ì´ì „)
                    pass
            
            print(f"[{category_name}] ë°œê²¬ëœ ìµœëŒ€ í˜ì´ì§€ ìˆ˜: {max_page_found}")
            total_pages = max_page_found
        except Exception as e:
            print(f"[{category_name}] í˜ì´ì§€ë„¤ì´ì…˜ í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
            # í˜ì´ì§€ë‹¹ ìƒí’ˆ ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ì´ í˜ì´ì§€ ìˆ˜ ì¶”ì •
            total_pages = (total_items + 47) // 48  # í˜ì´ì§€ë‹¹ ì•½ 48ê°œ ìƒí’ˆ ê¸°ì¤€
        
        # ìµœëŒ€ í˜ì´ì§€ ìˆ˜ ì œí•œ
        if max_pages:
            total_pages = min(total_pages, max_pages)
        
        print(f"[{category_name}] í¬ë¡¤ë§í•  ì´ í˜ì´ì§€ ìˆ˜: {total_pages}")
        
        # ëª¨ë“  í˜ì´ì§€ í¬ë¡¤ë§
        current_page = 1
        
        while current_page <= total_pages:
            print(f"[{category_name}] í˜„ì¬ í˜ì´ì§€: {current_page}/{total_pages}")
            
            # í˜„ì¬ í˜ì´ì§€ì˜ ìƒí’ˆ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
            try:
                # ìƒí’ˆ ì»¨í…Œì´ë„ˆë“¤ì„ ëª¨ë‘ ì°¾ìŒ
                products = WebDriverWait(driver, 10).until(
                    EC.presence_of_all_elements_located((By.CSS_SELECTOR, '.xans-element-.xans-product.xans-product-listnormal ul.prdList li.item'))
                )
                
                print(f"[{category_name}] í˜ì´ì§€ì—ì„œ {len(products)}ê°œì˜ ìƒí’ˆ í•­ëª© ë°œê²¬")
                
                # ê° ìƒí’ˆ ìš”ì†Œì—ì„œ ì •ë³´ ì¶”ì¶œ
                products_on_current_page = []
                for idx, product_element in enumerate(products, 1):
                    print(f"[{category_name}] ìƒí’ˆ {idx}/{len(products)} ì²˜ë¦¬ ì¤‘...")
                    product_info = extract_product_info(product_element)
                    if product_info:
                        # ì¹´í…Œê³ ë¦¬ ì •ë³´ ì¶”ê°€ - ì¹´í…Œê³ ë¦¬ ëìŠ¤ êµ¬ë¶„
                        product_info['ì¹´í…Œê³ ë¦¬_ëŒ€ë¶„ë¥˜'] = main_category
                        product_info['ì¹´í…Œê³ ë¦¬_ì†Œë¶„ë¥˜'] = sub_category
                        product_info['ì¹´í…Œê³ ë¦¬_ì „ì²´'] = category_name
                        products_on_current_page.append(product_info)
                        print(f"[{category_name}] ìƒí’ˆ {idx} ì •ë³´ ì¶”ì¶œ ì„±ê³µ: {product_info['ìƒí’ˆëª…']}")
                
                print(f"[{category_name}] í˜ì´ì§€ì—ì„œ ì„±ê³µì ìœ¼ë¡œ ì¶”ì¶œí•œ ìƒí’ˆ ìˆ˜: {len(products_on_current_page)}")
                all_products.extend(products_on_current_page)
                print(f"[{category_name}] í˜„ì¬ê¹Œì§€ ìˆ˜ì§‘ëœ ì´ ìƒí’ˆ ìˆ˜: {len(all_products)}")
                
                # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
                if current_page < total_pages:
                    next_page_success = False
                    
                    # ë°©ë²• 1: í˜ì´ì§€ ë²ˆí˜¸ í´ë¦­
                    try:
                        # í˜ì´ì§€ ë§í¬ ë‹¤ì‹œ ì°¾ê¸° (DOMì´ ë³€ê²½ë˜ì—ˆì„ ìˆ˜ ìˆìŒ)
                        pagination = driver.find_elements(By.CSS_SELECTOR, '.ec-base-paginate li a')
                        for page_link in pagination:
                            if page_link.text.strip() == str(current_page + 1):
                                page_link.click()
                                next_page_success = True
                                time.sleep(3)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
                                break
                    except Exception as e:
                        print(f"[{category_name}] í˜ì´ì§€ í´ë¦­ ë°©ì‹ ì‹¤íŒ¨: {e}")
                    
                    # ë°©ë²• 2: URL ì§ì ‘ ë³€ê²½
                    if not next_page_success:
                        try:
                            base_url = url.split('&page=')[0] if '&page=' in url else url
                            next_page_url = f"{base_url}&page={current_page + 1}"
                            print(f"[{category_name}] ë‹¤ìŒ í˜ì´ì§€ URL: {next_page_url}")
                            driver.get(next_page_url)
                            next_page_success = True
                            time.sleep(3)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
                        except Exception as e:
                            print(f"[{category_name}] URL ë³€ê²½ ë°©ì‹ ì‹¤íŒ¨: {e}")
                
                current_page += 1
                
                # ì„œë²„ ë¶€ë‹´ ê°ì†Œë¥¼ ìœ„í•œ ëŒ€ê¸°
                delay = random.uniform(2, 5)
                print(f"[{category_name}] {delay:.2f}ì´ˆ ëŒ€ê¸° ì¤‘...")
                time.sleep(delay)
                
            except Exception as e:
                print(f"[{category_name}] í˜ì´ì§€ {current_page} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                break
    
    except Exception as e:
        print(f"[{category_name}] í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    finally:
        driver.quit()
    
    return all_products

def extract_category_urls(html_content):
    """HTMLì—ì„œ ì¹´í…Œê³ ë¦¬ URL ì¶”ì¶œ"""
    soup = BeautifulSoup(html_content, 'html.parser')
    category_links = []
    
    # ë“œë¡œì–´ ë©”ë‰´ì—ì„œ ë©”ì¸ ì¹´í…Œê³ ë¦¬ì™€ ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
    drawer_category = soup.select('.drawercategory .drawerbox')
    
    for box in drawer_category:
        main_categories = box.select('li.-d1')
        
        for main_category in main_categories:
            main_link = main_category.select_one('a')
            if not main_link:
                continue
                
            main_category_name = main_link.text.strip()
            main_url = main_link.get('href', '')
            
            # ì ˆëŒ€ URLë¡œ ë³€í™˜
            if main_url.startswith('/'):
                main_url = f"https://baddiary.com{main_url}"
            
            # ì„œë¸Œì¹´í…Œê³ ë¦¬ê°€ ìˆëŠ”ì§€ í™•ì¸
            has_sub = main_category.has_attr('class') and 'hasChild' in main_category['class']
            
            if has_sub:
                # ì„œë¸Œ ì¹´í…Œê³ ë¦¬ ì¶”ì¶œ
                sub_categories = main_category.select('ul.-subcover1 li.-d2')
                for sub_category in sub_categories:
                    sub_link = sub_category.select_one('a')
                    if not sub_link:
                        continue
                        
                    sub_category_name = sub_link.text.strip()
                    sub_url = sub_link.get('href', '')
                    
                    # ì ˆëŒ€ URLë¡œ ë³€í™˜
                    if sub_url.startswith('/'):
                        sub_url = f"https://baddiary.com{sub_url}"
                        
                    # ì¹´í…Œê³ ë¦¬ ì •ë³´ ì €ì¥
                    category_links.append({
                        'main_category': main_category_name,
                        'sub_category': sub_category_name,
                        'url': sub_url
                    })
            else:
                # ì„œë¸Œ ì¹´í…Œê³ ë¦¬ê°€ ì—†ëŠ” ê²½ìš° ë©”ì¸ ì¹´í…Œê³ ë¦¬ë§Œ ì¶”ê°€
                category_links.append({
                    'main_category': main_category_name,
                    'sub_category': '',
                    'url': main_url
                })
    
    return category_links

def main():
    try:
        # HTML ë¬¸ìì—´ì—ì„œ ì¹´í…Œê³ ë¦¬ URL ì¶”ì¶œ
        html_content = """
        <aside id="drawermenuwrap" class="drawermenuwrap2 d1popupwrap D1W" style="display: block;"><div class="drawermenu -frame -flex">
                    <!-- ê´€ë¦¬ì ì—°ë™ -->
                    <!--<div class="drawercategory"><ul id="drawercategorydata" class="-flex"></ul></div>-->
                    <!-- HTML ì½”ë”© -->
                    <div class="drawercategory -flex"><ul class="drawerbox"><li cateno="36" class="-d1 d1ddm"><a href="/product/list.html?cate_no=36">BEST</a></li>
    <li cateno="72" class="-d1 d1ddm"><a href="/product/list.html?cate_no=72">NEW 5%</a></li>
    <li cateno="69" class="-d1 d1ddm"><a href="/product/list.html?cate_no=69">MADE</a></li>
    <li cateno="33" class="-d1 d1ddm"><a href="/product/list.html?cate_no=33">ì˜¤ëŠ˜ì¶œë°œğŸšš</a></li>
</ul><ul class="drawerbox"><li cateno="24" class="-d1 d1ddm hasChild">
        <a href="/product/list.html?cate_no=24">DRESS<div class="icon"></div></a>
        <ul class="-subcover1 submenu"><li cateno="173" class="-d2"><a href="/product/list.html?cate_no=173">í”„ë¦°íŠ¸</a></li>
            <li cateno="175" class="-d2"><a href="/product/list.html?cate_no=175">ì†”ë¦¬ë“œ(ë¬´ì§€)</a></li>
            <li cateno="176" class="-d2"><a href="/product/list.html?cate_no=176">Hë¼ì¸</a></li>
            <li cateno="177" class="-d2"><a href="/product/list.html?cate_no=177">í”Œë ˆì–´&amp;Aë¼ì¸</a></li>
        </ul></li>
</ul><ul class="drawerbox"><li cateno="25" class="-d1 d1ddm hasChild">
        <a href="/product/list.html?cate_no=25">OUTER<div class="icon"></div></a>
        <ul class="-subcover1 submenu"><li cateno="177" class="-d2"><a href="/product/list.html?cate_no=51">ê°€ë””ê±´</a></li>
            <li cateno="52" class="-d2"><a href="/product/list.html?cate_no=52">ìì¼“/ì½”íŠ¸</a></li>
            <li cateno="418" class="-d2"><a href="/product/list.html?cate_no=418">íŒ¨ë”©</a></li>
        </ul></li>
</ul><ul class="drawerbox"><li cateno="42" class="-d1 d1ddm hasChild">
        <a href="/product/list.html?cate_no=42">TOP<div class="icon"></div></a>
        <ul class="-subcover1 submenu"><li cateno="46" class="-d2"><a href="/product/list.html?cate_no=46">ë¸”ë¼ìš°ìŠ¤</a></li>
            <li cateno="45" class="-d2"><a href="/product/list.html?cate_no=45">í‹°/ë‹ˆíŠ¸</a></li>
        </ul></li>
</ul><ul class="drawerbox"><li cateno="27" class="-d1 d1ddm hasChild">
        <a href="/product/list.html?cate_no=27">BOTTOM<div class="icon"></div></a>
        <ul class="-subcover1 submenu"><li cateno="48" class="-d2"><a href="/product/list.html?cate_no=48">íŒ¬ì¸ </a></li>
            <li cateno="49" class="-d2"><a href="/product/list.html?cate_no=49">ìŠ¤ì»¤íŠ¸</a></li>
        </ul></li>
</ul><ul class="drawerbox"><li cateno="28" class="-d1 d1ddm"><a href="/product/list.html?cate_no=28">ACC</a></li>
    <li cateno="227" class="-d1 d1ddm"><a href="/product/list.html?cate_no=227">ì¶œê·¼ë£©</a></li>
    <li cateno="35" class="-d1 d1ddm"><a href="/product/list.html?cate_no=35">ì›¨ë”©&amp;ì„¸ë ˆë¨¸ë‹ˆ</a></li>
    <li cateno="152" class="-d1 d1ddm"><a href="/product/list.html?cate_no=152">ë² ì´ì§</a></li>
    <li cateno="320" class="-d1 d1ddm"><a href="/product/list.html?cate_no=320">ì…‹ì—…</a></li>
    <li cateno="445" class="-d1 d1ddm"><a href="/product/list.html?cate_no=445">ì—¬í–‰ë£©âœˆï¸</a></li>
	<li cateno="31" class="-d1 d1ddm"><a href="/product/list.html?cate_no=43">77SIZE</a></li>
	<li cateno="31" class="-d1 d1ddm"><a href="/product/list.html?cate_no=31">ì•„ìš¸ë ›</a></li>
</ul></div>
                </div>
            </aside>
        """
        
        # ì¶”ì¶œëœ ì¹´í…Œê³ ë¦¬ URL ì •ë³´ë¥¼ CSVë¡œ ì €ì¥ (ì„ íƒì )
        category_links = extract_category_urls(html_content)
        df_categories = pd.DataFrame(category_links)
        df_categories.to_csv('baddiary_categories.csv', index=False, encoding='utf-8-sig')
        print(f"ì¹´í…Œê³ ë¦¬ ì •ë³´ CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: baddiary_categories.csv")
        
        print(f"ì´ {len(category_links)}ê°œì˜ ì¹´í…Œê³ ë¦¬ URLì„ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
        
        # ëª¨ë“  ì¹´í…Œê³ ë¦¬ì˜ ìƒí’ˆ ì •ë³´
        all_products_all_categories = []
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ í¬ë¡¤ë§
        for i, category in enumerate(category_links, 1):
            main_category = category['main_category']
            sub_category = category['sub_category']
            category_url = category['url']
            category_name = f"{main_category} > {sub_category}" if sub_category else main_category
            
            print(f"\n===== ({i}/{len(category_links)}) {category_name} ì¹´í…Œê³ ë¦¬ í¬ë¡¤ë§ ì‹œì‘ =====")
            print(f"URL: {category_url}")
            
            # ìµœëŒ€ í˜ì´ì§€ ìˆ˜ ì„¤ì • (Noneìœ¼ë¡œ ì„¤ì •í•˜ë©´ ëª¨ë“  í˜ì´ì§€)
            max_pages = 2  # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ê° ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ 2í˜ì´ì§€ë§Œ í¬ë¡¤ë§
            
            # ì…€ë ˆëŠ„ìœ¼ë¡œ í¬ë¡¤ë§ ì‹¤í–‰
            category_products = crawl_products(category_url, category, max_pages)
            
            # ì „ì²´ ìƒí’ˆ ëª©ë¡ì— ì¶”ê°€
            all_products_all_categories.extend(category_products)
            
            # ì„œë²„ ë¶€ë‹´ ê°ì†Œë¥¼ ìœ„í•œ ëŒ€ê¸°
            if i < len(category_links):
                delay = random.uniform(5, 10)
                print(f"ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ë¡œ ì´ë™í•˜ê¸° ì „ {delay:.2f}ì´ˆ ëŒ€ê¸° ì¤‘...")
                time.sleep(delay)
        
        # ëª¨ë“  ì¹´í…Œê³ ë¦¬ì˜ ìƒí’ˆì„ í•˜ë‚˜ì˜ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í†µí•©
        if all_products_all_categories:
            # ì¤‘ë³µ ì œê±° (ëª¨ë“  ì¹´í…Œê³ ë¦¬ì—ì„œ ë°œìƒí•  ìˆ˜ ìˆëŠ” ì¤‘ë³µ)
            unique_all_products = []
            product_urls = set()  # URL ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì²´í¬ (ê°™ì€ ìƒí’ˆëª…ì´ì§€ë§Œ ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ì— ìˆì„ ìˆ˜ ìˆìŒ)
            
            for product in all_products_all_categories:
                if product['ìƒí’ˆURL'] not in product_urls and product['ìƒí’ˆURL'].strip() != '':
                    product_urls.add(product['ìƒí’ˆURL'])
                    unique_all_products.append(product)
            
            print(f"\nëª¨ë“  ì¹´í…Œê³ ë¦¬ ì›ë³¸ ìƒí’ˆ ìˆ˜: {len(all_products_all_categories)}, ì¤‘ë³µ ì œê±° í›„ ìƒí’ˆ ìˆ˜: {len(unique_all_products)}")
            
            # í†µí•© ë°ì´í„°í”„ë ˆì„ ìƒì„±
            df_all = pd.DataFrame(unique_all_products)
            
            # CSV íŒŒì¼ë¡œ ì €ì¥
            all_csv_filename = 'baddiary_products_data.csv'
            df_all.to_csv(all_csv_filename, index=False, encoding='utf-8-sig')
            print(f"ëª¨ë“  ì¹´í…Œê³ ë¦¬ í†µí•© CSV íŒŒì¼ ì €ì¥ ì™„ë£Œ: {all_csv_filename}")
            
            # Excel íŒŒì¼ë¡œ ì €ì¥
            all_excel_filename = 'baddiary_products_data.xlsx'
            df_all.to_excel(all_excel_filename, index=False)
            print(f"ëª¨ë“  ì¹´í…Œê³ ë¦¬ í†µí•© Excel íŒŒì¼ ì €ì¥ ì™„ë£Œ: {all_excel_filename}")
        
        print(f"\ní¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(unique_all_products)}ê°œì˜ ìƒí’ˆ ì •ë³´ë¥¼ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
    
    except Exception as e:
        print(f"ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()